[{"content":"GitHubのWiki-Roadmapが更新されていました。\n技術的な負債とチームの速度 プロジェクトの全体的な速度を上げる。\n技術的負債の削減を行い、新しい人々がチームに参加し、生産性を上げるために、プロセスを改善する。\n問題のバックログに時間を費やし、時代遅れまたは実行不可能な問題を修正し、残りの問題に優先順位を付ける予定。\nパフォーマンス パフォーマンスの改善は最優先事項である。\nシェーダーコンパイラジャンクの問題を、まずは iOS で改善し、次に Android に取り組む。\nWeb では Wasm をサポートする。カスタムシェーダーのパフォーマンスを改善する。\n品質 アクセシビリティはFlutterアプリケーションにとって重要であり、すべてのプラットフォームでのアクセシビリティサポートの品質を向上させる。\n同様に、ドキュメントを改善し続けることが重要。\nまた、各プラットフォーム、特に動きの速い Android と iOS で最新の機能に対応し続けていく。\n（例えば iOS の Cupertino ウィジェット、 Android カメラプラグインの CameraX API への移行）\nセキュリティ SLSA-4 を継続することを視野に、今年、主要なリポジトリの SLSA-3 に到達することを目標に、 SLSA コンプライアンスに引き続き取り組む。\n新機能 Custom asset transformers Efficient 2D scrolling widgets Multiple windows Drag and drop Wireless debugging on iOS Custom \u0026ldquo;flutter create\u0026rdquo; templates 実装予定無し Web 上でのホットリロード ウェアラブル端末対応 Apple CarPlay 対応 Android Auto 対応 SEO サポート homebrew によるインストール ","description":"","id":0,"section":"posts","tags":["flutter","Dart"],"title":"【Flutter】2023年のロードマップ","uri":"https://tommylife88.github.io/posts/2023/2023-01-28-flutter-roadmap-2023/"},{"content":"GPUありのWindowsマシンのWSL2に機械学習環境を立てた。\nWSL2 インストール済み前提。\n1 2 3 4 5 6 7 8 9 10 11 $ wsl -l -v NAME STATE VERSION * Ubuntu Stopped 2 $ wsl --status 既定の配布: Ubuntu 既定のバージョン: 2 Linux 用 Windows サブシステムの最終更新日: 2022/03/27 WSL の自動更新が有効になっています。 カーネル バージョン: 5.10.102.1 NVIDIAドライバのインストール（on Windows） WSL2ではなくてWindowsにインストールする。\nhttps://developer.nvidia.com/cuda-downloads?target_os=Windows\u0026amp;target_arch=x86_64\u0026amp;target_version=11\u0026amp;target_type=exe_network\nインストール完了後、nvidia-smiが実行できればOK。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 $ nvidia-smi +-----------------------------------------------------------------------------+ | NVIDIA-SMI 516.01 Driver Version: 516.01 CUDA Version: 11.7 | |-------------------------------+----------------------+----------------------+ | GPU Name TCC/WDDM | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 NVIDIA GeForce ... WDDM | 00000000:01:00.0 Off | N/A | | N/A 60C P3 20W / N/A | 0MiB / 6144MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ WSL2 Ubuntu 20.04 上に機械学習環境を構築 CUDA 11.5 https://developer.nvidia.com/cuda-11-5-2-download-archive?target_os=Linux\u0026amp;target_arch=x86_64\u0026amp;Distribution=WSL-Ubuntu\u0026amp;target_version=2.0\u0026amp;target_type=deb_local\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 # install cuda $ wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin $ sudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600 $ wget https://developer.download.nvidia.com/compute/cuda/11.5.2/local_installers/cuda-repo-wsl-ubuntu-11-5-local_11.5.2-1_amd64.deb $ sudo dpkg -i cuda-repo-wsl-ubuntu-11-5-local_11.5.2-1_amd64.deb $ sudo apt-key add /var/cuda-repo-wsl-ubuntu-11-5-local/7fa2af80.pub $ sudo apt-get update $ sudo apt-get -y install cuda # set env $ echo \u0026#39;export CUDA_PATH=/usr/local/cuda-11.5\u0026#39; \u0026gt;\u0026gt; ${HOME}/.bashrc $ echo \u0026#39;export LD_LIBRARY_PATH=/usr/local/cuda-11.5/lib64:${LD_LIBRARY_PATH}\u0026#39; \u0026gt;\u0026gt; ${HOME}/.bashrc $ echo \u0026#39;export PATH=/usr/local/cuda-11.5/bin:${PATH}\u0026#39; \u0026gt;\u0026gt; ${HOME}/.bashrc $ echo \u0026#39;export CUDA_VISIBLE_DEVICES=0\u0026#39; \u0026gt;\u0026gt; ${HOME}/.bashrc $ source ${HOME}/.bashrc $ nvcc --version nvcc: NVIDIA (R) Cuda compiler driver Copyright (c) 2005-2021 NVIDIA Corporation Built on Thu_Nov_18_09:45:30_PST_2021 Cuda compilation tools, release 11.5, V11.5.119 Build cuda_11.5.r11.5/compiler.30672275_0 $ cat /usr/local/cuda-11.5/version.json ❮  130 { \u0026#34;cuda\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA SDK\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.2\u0026#34; }, \u0026#34;cuda_cudart\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA Runtime (cudart)\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.117\u0026#34; }, \u0026#34;cuda_cuobjdump\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;cuobjdump\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.119\u0026#34; }, \u0026#34;cuda_cupti\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUPTI\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.114\u0026#34; }, \u0026#34;cuda_cuxxfilt\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA cu++ filt\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.119\u0026#34; }, \u0026#34;cuda_demo_suite\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA Demo Suite\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.50\u0026#34; }, \u0026#34;cuda_gdb\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA GDB\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.114\u0026#34; }, \u0026#34;cuda_memcheck\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA Memcheck\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.114\u0026#34; }, \u0026#34;cuda_nsight\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;Nsight Eclipse Plugins\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.114\u0026#34; }, \u0026#34;cuda_nvcc\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA NVCC\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.119\u0026#34; }, \u0026#34;cuda_nvdisasm\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA nvdisasm\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.119\u0026#34; }, \u0026#34;cuda_nvml_dev\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA NVML Headers\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.50\u0026#34; }, \u0026#34;cuda_nvprof\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA nvprof\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.114\u0026#34; }, \u0026#34;cuda_nvprune\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA nvprune\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.119\u0026#34; }, \u0026#34;cuda_nvrtc\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA NVRTC\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.119\u0026#34; }, \u0026#34;cuda_nvtx\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA NVTX\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.114\u0026#34; }, \u0026#34;cuda_nvvp\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA NVVP\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.126\u0026#34; }, \u0026#34;cuda_samples\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA Samples\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.56\u0026#34; }, \u0026#34;cuda_sanitizer_api\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA Compute Sanitizer API\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.114\u0026#34; }, \u0026#34;cuda_thrust\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA C++ Core Compute Libraries\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.62\u0026#34; }, \u0026#34;libcublas\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA cuBLAS\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.7.4.6\u0026#34; }, \u0026#34;libcufft\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA cuFFT\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;10.6.0.107\u0026#34; }, \u0026#34;libcufile\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;GPUDirect Storage (cufile)\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;1.1.1.25\u0026#34; }, \u0026#34;libcurand\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA cuRAND\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;10.2.7.107\u0026#34; }, \u0026#34;libcusolver\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA cuSOLVER\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.3.2.107\u0026#34; }, \u0026#34;libcusparse\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA cuSPARSE\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.7.0.107\u0026#34; }, \u0026#34;libnpp\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA NPP\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.1.107\u0026#34; }, \u0026#34;libnvjpeg\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;CUDA nvJPEG\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;11.5.4.107\u0026#34; }, \u0026#34;nsight_compute\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;Nsight Compute\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;2021.3.1.4\u0026#34; }, \u0026#34;nsight_systems\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;Nsight Systems\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;2021.3.3.2\u0026#34; }, \u0026#34;nvidia_fs\u0026#34; : { \u0026#34;name\u0026#34; : \u0026#34;NVIDIA file-system\u0026#34;, \u0026#34;version\u0026#34; : \u0026#34;2.9.5\u0026#34; } } # Build sample program $ sudo apt-get install -y g++ freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libglu1-mesa libglu1-mesa-dev $ sudo rm -rf cuda-samples \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 $ sudo git clone https://github.com/NVIDIA/cuda-samples.git $ cd cuda-samples/Samples/1_Utilities/deviceQuery/ $ sudo make $ sudo ./deviceQuery $ cd ../../../../cuda-samples/Samples/1_Utilities/bandwidthTest/ $ sudo make $ sudo ./bandwidthTest $ cd ../../../../cuda-samples/Samples/4_CUDA_Libraries/simpleCUBLAS $ sudo make $ sudo ./simpleCUBLAS $ cd ../../../../cuda-samples/Samples/4_CUDA_Libraries/simpleCUFFT/ $ sudo make $ sudo ./simpleCUFFT cuDNN 8.33 https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installlinux-deb\nhttps://developer.nvidia.com/rdp/cudnn-archive\n1 2 3 4 5 $ sudo dpkg -i cudnn-local-repo-ubuntu2004-8.3.3.40_1.0-1_amd64.deb $ sudo cp /var/cudnn-local-repo-ubuntu2004-8.3.3.40/cuda-ubuntu2004.pin /usr/share/keyrings/ $ sudo apt-get -y update $ apt-cache search cudnn $ sudo apt-get -y install libcudnn8 libcudnn8-dev Anaconda https://www.anaconda.com/\n1 2 $ bash Anaconda3-2022.05-Linux-x86_64.sh # 言われるがままに従う TensorFlow GPU https://www.tensorflow.org/install/pip?hl=ja\nTensorFlow 2以降はGPUもCPUも同じパッケージらしい。\nconda installでうまくいかなかったので、pip installした。\n1 2 3 4 5 6 7 # ランタイムエラーになるので… $ sudo ln -s /usr/local/cuda-11.5/lib64/libcusolver.so.11 /usr/local/cuda-11.5/lib64/libcusolver.so.10 $ conda create -n tf python=3.9 $ conda activate tf (tf) $ pip install tensorflow==2.9.1 (tf) $ conda install jupyterlab -y (tf) $ jupyter lab --no-browser 動作確認。\n1 2 3 4 5 import tensorflow as tf from tensorflow.python.client import device_lib print( tf.__version__ ) print(device_lib.list_local_devices()) PyTorch https://pytorch.org/get-started/locally/\n1 2 3 4 5 6 $ conda deactivate $ conda create -n torch python=3.9 $ conda activate torch (torch) $ conda install pytorch torchvision torchaudio cudatoolkit=11.3 -c pytorch -y (torch) $ conda install jupyterlab -y (torch) $ jupyter lab --no-browser 動作確認。\n1 2 3 4 import torch print(torch.__version__, torch.cuda.is_available()) x = torch.rand(5, 3) print(x) ","description":"","id":1,"section":"posts","tags":["ML","Anaconda","TensorFlow","PyTorch"],"title":"WSL2に機械学習環境を構築（NVIDIA GPU, Anaconda, TensorFlow, PyTorch）","uri":"https://tommylife88.github.io/posts/2022/2022-06-14-nvidia-gpu-anaconda-tf-torch/"},{"content":"プロジェクト毎にFlutter SDKのバージョンを切り替えたい。\nFVM(Flutter Version Management)\nhttps://fvm.app/\nインストールした手順 Flutterの要件を満たしている前提。\nhttps://fvm.app/docs/getting_started/installation をみる。\nインストール済みのFlutterがあれば削除しておくのが安心。\nMacOS Homebrewパッケージから。\n1 2 brew tap leoafarias/fvm brew install fvm Windows スタンドアローンがお手軽。\nスタンドアローン（推奨） FVM自体のアップデートは手動になるけど、下記chocoをインストールするのが嫌ならこちらのほうがお手軽。\nバイナリを取得する。\nhttps://github.com/leoafarias/fvm/releases\n適当なディレクトリに展開する（以下はユーザーディレクトリのtoolsとしている）。\nC:\\Users\\\u0026lt;username\u0026gt;\\tools\\fvm\n環境変数PATHにC:\\Users\\\u0026lt;username\u0026gt;\\tools\\fvmを追加する。\n1 2 # fvm のインストール確認 fvm doctor choco chocoインストール\nhttps://chocolatey.org/install\n※fvmがwingetで取得できればなあ…仕方ない…\n1 2 3 4 5 6 # choco のインストール確認 choco -v # choco で fvm インストール choco install fvm # fvm のインストール確認 fvm doctor ここまでがfvmのインストール。\n使い方 1 2 3 4 5 6 7 8 9 # インストール可能なバージョンの一覧表示 fvm releases # 複数バージョンのインストール fvm install 2.8.1 fvm install 2.10.1 # インストール済みのバージョンを表示 fvm list プロジェクトの設定 ■Flutterプロジェクトを作成済み場合\n1 2 3 cd \u0026lt;project dir\u0026gt; fvm use 2.10.1 # fvm use stable #channelの指定もOK ■Flutterプロジェクトが未作成の場合\n1 2 3 4 5 mkdir fvm_test cd fvm_test fvm use 2.10.1 --force # fvm use stable #channelの指定もOK fvm flutter create . 自動生成される.fvm\\fvm_config.jsonをコミットすることで、チームでバージョンを統一できる。\nVSCodeや.gitignoreの設定はこちら。\nhttps://fvm.app/docs/getting_started/configuration\n最後に、doctorで正しくSDKを認識しているか確認しておく。\n1 2 fvm doctor fvm flutter doctor TIPS エイリアス FVM管理のFlutter SDKのコマンドを実行する際にfvm flutter XXXや、fvm dart XXXのようにfvmのコマンドが必要になる。\nこれはエイリアスで解決できる。\nglobal化 プロジェクトとは関係の無いところでFVMで取得したSDKを使用したい場合、globalコマンドが使える。\nglobalで指定したバージョンがfvm無しに実行できる。\n1 2 3 4 # global には stable チャネルを指定 fvm global stable # fvm 無しで global に指定したSDKが参照される flutter doctor flavor プロジェクトの中でも複数のSDKを切り替えることができる。\nhttps://fvm.app/docs/guides/project_flavors\n1 2 3 4 5 6 7 { \u0026#34;flutterSdkVersion\u0026#34;: \u0026#34;stable\u0026#34;, \u0026#34;flavors\u0026#34;: { \u0026#34;beta\u0026#34;: \u0026#34;beta\u0026#34;, \u0026#34;prod\u0026#34;: \u0026#34;2.10.1\u0026#34; } } betaとしてbetaバージョンを、prodとして2.10.1を指定した例。\nfvm flavorで切り替える。\n1 2 3 4 5 6 7 8 9 \u0026gt; fvm flavor Project flavors configured for \u0026#34;fvm_test\u0026#34;: [1] beta [2] prod Select an environment:1 #1を入力 Switching to [beta] flavor, which uses [beta] Flutter sdk. Now using [beta] flavor. Flutter version [beta]. ","description":"","id":2,"section":"posts","tags":["Flutter","FVM"],"title":"【FVM】Flutter SDKの複数バージョン管理","uri":"https://tommylife88.github.io/posts/2022/2022-02-15-flutter-fvm/"},{"content":"いつも忘れるんだよなあ。\nsubmoduleありのリポジトリをcloneする際、\n1 git clone --recursive \u0026lt;repo url\u0026gt; でsubmoduleをcloneできるところを、--recursiveをつけ忘れてしまう。\n対処法 cloneしたディレクトリに移動して、\n1 git submodule update --init --recursive でsubmoduleを後からcloneできる。\n","description":"","id":3,"section":"posts","tags":["Git"],"title":"Git cloneで--recursive忘れて、後からsubmoduleをcloneしたいときの対処","uri":"https://tommylife88.github.io/posts/2022/2022-02-09-git-submodule-init-lator/"},{"content":"Dartの..や?..って何？ってよく聞かれるので。\n【公式】Cascade notation（カスケード記法）って呼ばれるもの。\nカスケード記法 機械翻訳すると、Dartのカスケード記法は以下のように説明されている。\n同じオブジェクトに対して一連の操作を行うことができます。関数呼び出しに加えて、同じオブジェクトのフィールドにアクセスすることもできます。これにより、一時変数を作成する手間が省け、より流動的なコードを記述できるようになります。\n例えば、\n1 2 3 4 var paint = Paint(); paint.color = Colors.black; paint.strokeCap = StrokeCap.round; paint.strokeWidth = 5.0; をカスケードで書き直すと、\n1 2 3 4 var paint = Paint() ..color = Colors.black ..strokeCap = StrokeCap.round ..strokeWidth = 5.0; とかける。\n直前に作ったpaintオブジェクトに対する関数呼び出しや、フィールドへのアクセスを短く記述できる。\nカスケード記法に続くコードは、返されるかもしれない値を無視して、このオブジェクトを操作する。\nnull-shortingカスケード カスケードが動作するオブジェクトがnullになる可能性がある場合は、?..で記述できる。\n2.12以降 1 2 3 4 var button = querySelector(\u0026#39;#confirm\u0026#39;); button?.text = \u0026#39;Confirm\u0026#39;; button?.classes.add(\u0026#39;important\u0026#39;); button?.onClick.listen((e) =\u0026gt; window.alert(\u0026#39;Confirmed!\u0026#39;)); は、\n1 2 3 4 querySelector(\u0026#39;#confirm\u0026#39;) // Get an object. ?..text = \u0026#39;Confirm\u0026#39; // Use its members. ..classes.add(\u0026#39;important\u0026#39;) ..onClick.listen((e) =\u0026gt; window.alert(\u0026#39;Confirmed!\u0026#39;)) と書ける。\n注意 戻り値voidの関数にカスケードするとエラーになる。\n1 2 3 var sb = StringBuffer(); sb.write(\u0026#39;foo\u0026#39;) ..write(\u0026#39;bar\u0026#39;); // Error: method \u0026#39;write\u0026#39; isn\u0026#39;t defined for \u0026#39;void\u0026#39;. この場合、sb.writeの戻り値がvoidなのでカスケードできない。理屈が分かればなんのこっちゃない。\n","description":"","id":4,"section":"posts","tags":["Dart"],"title":"Dartのカスケード記法（../?..）","uri":"https://tommylife88.github.io/posts/2022/2022-01-26-dart-cascade-notation/"},{"content":"GitHubのWiki-Roadmapが更新されていました。\nフォーカスする領域 開発者体験 開発者が愛するSDKにする。\n一般的な問題を解決するWidgetやPluginの作成 既存のAPIの整理 頻繁に見られるパターンを簡素化するための新しいAPIの導入 エラーメッセージの改善 開発者ツールとIDEプラグインの改善 新しいLintの作成 フレームワークとエンジンのバグの修正 APIドキュメントの改善 より有用なサンプルの作成 Web上でのホットリロード Dart-to-JSシナリオでのスタックトレースを改善 Desktop デスクトップサポートをstableチャネルにあげる。\nWindowsに始まり、Linux、macOSと一つづつプラットフォームをテストし、リリースする予定。この取り組みの重要な部分として、リグレッションテストスイートを拡張して、既存のコードを壊すことなく拡大すること。\nWeb 以下の改善、向上に取り組む。\nパフォーマンス プラグインの品質 アクセシビリティ アクセシビリティ また、FlutterアプリをFlutter以外のHTMLに埋め込みやすくする予定。\nフレームワーク、エンジン Materialライブラリを更新して、Material 3をサポート予定（issue）。これは主に、Androidに忠実に向上させるためだが、プラットフォームに限定されない。\ncross-widget text selectionなるWidgetを実装したい。これは、ウェブプラットフォームにより忠実であるという目標を達成するためだが、ウェブに限定されるわけではない。\nデスクトップのテキスト編集やiPadOSの手書き文字認識など、全てのプラットフォームでテキスト編集を改善させたい。\nデスクトップとWebに対して実装されるOSに沿ったコンテキストメニューやメニューバーをリリースする予定。\nまた、ホストOS（特にmacOS）に沿ったメニュー（コンテキストメニューとメニューバー）をリリースする。\nプラットフォームに限らず、単一のIsolateから、複数のウィンドウへのレンダリングをサポートすることを試みるつもり。\nDart 静的メタプログラミングのような大きな機能と、パッケージのインポート構文の改善を含むいくつかの小さな改良を行う。\nまた、WasmGCのタイムリーな標準化に応じてWasmへコンパイルするために、Dartのコンパイルツールチェーンを拡張する予定。\nJank ユーザー体験の低下を引き起こすこと 2021年にはjankに関する多くのissueを解決してきたが、シェーダーをどう使うか再考する必要があると結論付けた。その結果、グラフィックスのバックエンドを再構築していった。\n2022年には、iOSのFlutterを新しいアーキテクチャに移行し、その経験に基づいて、他のプラットフォームに移植する作業を開始していく予定。また、新しいDisplayListシステムが実現した機能など、パフォーマンスの向上やパフォーマンスの自己観察要素を実装していく。\n非推奨になること 32ビットiOSのサポートを終了予定としている。\nInfrastructure サプライチェーンのセキュリティへの投資を拡大し、インフラをSLSA Level 4に記載された要件に一致させる予定。\nGoogleが提案しているソフトウェアサプライチェーン攻撃の脅威拡大に対処する手段 ","description":"","id":5,"section":"posts","tags":["flutter","Dart"],"title":"【Flutter】2022年のロードマップ","uri":"https://tommylife88.github.io/posts/2022/2022-01-16-flutter-roadmap-2022/"},{"content":"Flutterハンズオン。ちょっと触れる機会があったので備忘録として。\nGoogleによって開発されたOSSなUIのSDK。単一のコードベースからクロスプラットフォームアプリケーションを開発するために利用できる。\n公式のドキュメントが充実していて、そこから理解していくのが間違いない。\nget started https://docs.flutter.dev/get-started\nTutorials https://docs.flutter.dev/get-started/codelab\nhttps://codelabs.developers.google.com/codelabs/first-flutter-app-pt2#0\nhttps://codelabs.developers.google.com/codelabs/flutter#0\nSamples https://flutter.github.io/samples/#\nYoutube https://www.youtube.com/channel/UCwXdFgeE9KYzlDdR7TG9cMw\nFlutter Widget of the Weak https://www.youtube.com/playlist?list=PLjxrf2q8roU23XGwz3Km7sQZFTdB996iG\nFlutter Package of the Weak https://www.youtube.com/playlist?list=PLjxrf2q8roU1quF6ny8oFHJ2gBdrYN_AK\nVSCode エディタはVSCode一択か。\nExtensions https://marketplace.visualstudio.com/items?itemName=marcelovelasquez.flutter-tree\nhttps://marketplace.visualstudio.com/items?itemName=alexisvt.flutter-snippets\nhttps://marketplace.visualstudio.com/items?itemName=Nash.awesome-flutter-snippets\nhttps://marketplace.visualstudio.com/items?itemName=usernamehw.errorlens\nhttps://marketplace.visualstudio.com/items?itemName=circlecodesolution.ccs-flutter-color\nSettings https://dartcode.org/docs/recommended-settings/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 { // Causes the debug view to automatically appear when a breakpoint is hit. This // setting is global and not configurable per-language. \u0026#34;debug.openDebug\u0026#34;: \u0026#34;openOnDebugBreak\u0026#34;, \u0026#34;[dart]\u0026#34;: { // Automatically format code on save and during typing of certain characters // (like `;` and `}`). \u0026#34;editor.formatOnSave\u0026#34;: true, \u0026#34;editor.formatOnType\u0026#34;: true, // Draw a guide line at 80 characters, where Dart\u0026#39;s formatting will wrap code. \u0026#34;editor.rulers\u0026#34;: [80], // Disables built-in highlighting of words that match your selection. Without // this, all instances of the selected text will be highlighted, interfering // with Dart\u0026#39;s ability to highlight only exact references to the selected variable. \u0026#34;editor.selectionHighlight\u0026#34;: false, // By default, VS Code prevents code completion from popping open when in // \u0026#34;snippet mode\u0026#34; (editing placeholders in inserted code). Setting this option // to `false` stops that and allows completion to open as normal, as if you // weren\u0026#39;t in a snippet placeholder. \u0026#34;editor.suggest.snippetsPreventQuickSuggestions\u0026#34;: false, // By default, VS Code will pre-select the most recently used item from code // completion. This is usually not the most relevant item. // // \u0026#34;first\u0026#34; will always select top item // \u0026#34;recentlyUsedByPrefix\u0026#34; will filter the recently used items based on the // text immediately preceding where completion was invoked. \u0026#34;editor.suggestSelection\u0026#34;: \u0026#34;first\u0026#34;, // Allows pressing \u0026lt;TAB\u0026gt; to complete snippets such as `for` even when the // completion list is not visible. \u0026#34;editor.tabCompletion\u0026#34;: \u0026#34;onlySnippets\u0026#34;, // By default, VS Code will populate code completion with words found in the // current file when a language service does not provide its own completions. // This results in code completion suggesting words when editing comments and // strings. This setting will prevent that. \u0026#34;editor.wordBasedSuggestions\u0026#34;: false, } } 追加で・・・\nコード上のガイド表示\n1 2 3 4 5 6 7 8 { // ガイド表示 \u0026#34;dart.previewFlutterUiGuides\u0026#34;: true, // 描画の遅延を防ぐ \u0026#34;dart.previewFlutterUiGuidesCustomTracking\u0026#34;: true, // クロージングラベルは表示する \u0026#34;dart.closingLabels\u0026#34;: true, } Dart https://dart.dev/\nWith Firebase https://firebase.google.com/docs/flutter/setup?hl=ja\u0026amp;platform=android\n","description":"","id":6,"section":"posts","tags":["flutter","Dart"],"title":"Flutterハンズオン","uri":"https://tommylife88.github.io/posts/2021/2021-11-05-flutter-handson/"},{"content":"M1 MacにNode.jsインストール。\nネットにはいろいろやり方があるけど自分用に整理した。\n（MacはAppleシリコンやらで情報が錯綜しがち、数ヶ月の情報も古かったり信用できなかったり・・）\n環境 Mac\n1 2 3 4 % sw_vers ProductName: macOS ProductVersion: 12.0.1 BuildVersion: 21A559 Homebrew\n1 2 3 4 % brew --version Homebrew 3.3.1-47-gdae9a34 Homebrew/homebrew-core (git revision 229487f07e1; last commit 2021-10-30) Homebrew/homebrew-cask (git revision 66bab33b26; last commit 2021-10-30) Node.js rbenvに慣れているので、Node.jsのバージョン管理にnodenvを使う。\nhttps://github.com/nodenv/nodenv\n公式の手順そのまま。\nインストール 1 2 % brew install nodenv % echo \u0026#39;eval \u0026#34;$(nodenv init -)\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc バージョン確認 1 2 % nodenv -v nodenv 1.4.0 Node.js本体をインストール とりあえず最新バージョン\n1 2 3 4 5 6 % nodenv install 16.13.0 % nodenv global 16.13.0 % node -v v16.13.0 % npm -v 8.1.0 インストールチェック 本当はインストール後にやるものだけど。\n1 2 3 4 5 6 % curl -fsSL https://github.com/nodenv/nodenv-installer/raw/master/bin/nodenv-doctor | bash Checking for `nodenv\u0026#39; in PATH: /opt/homebrew/bin/nodenv Checking for nodenv shims in PATH: OK Checking `nodenv install\u0026#39; support: /opt/homebrew/bin/nodenv-install (node-build 4.9.61) Counting installed Node versions: 1 versions Auditing installed plugins: OK Yarn Homebrewからインストールした（意図的にnodeからインストールしていない）。\nインストール --ignore-dependenciesを付与して、nodeの依存関係を無視している。Warningでたけど気にしない。。。\n1 2 3 % brew install yarn --ignore-dependencies % yarn --version 1.22.17 ","description":"","id":7,"section":"posts","tags":["Mac","MacM1","Node","Nodenv","Yarn"],"title":"M1 MacにNode.jsとYarnをインストール","uri":"https://tommylife88.github.io/posts/2021/2021-10-31-install-nodejs-yarn-to-mac-m1/"},{"content":"軽量マークアップ言語でメジャーといえばmarkdownだけど、より高度な文書の論理構造を構築することが可能なAsciiDocが良き。\n公式にあるのだけど自分の理解も兼ねてのチートシート作った。\nついでにAsciiDoc執筆環境をbundlerで揃えた。\nチートシート github pagesにデプロイした。\nhttps://tommylife88.github.io/asciidoc/\n執筆環境 Ruby bundlerを使う。\nbundle installを実行するだけで、Asciidoctorなどの周辺ツールをサンドボックス環境で揃えることができる。\nGemfile.lockファイルも置いたので環境を再現しやすいように。\nせっかくなのでRakefileでHTMLやPDF変換をタスク化している。\n","description":"","id":8,"section":"posts","tags":["AsciiDoc","Asciidoctor"],"title":"AsciiDocチートシートを作った","uri":"https://tommylife88.github.io/posts/2021/2021-10-29-asciidoc/"},{"content":"PowerShellのジョブのバックグラウンド実行したい。Start-Jobめんどくさい。Linuxみたく、演算子\u0026quot;\u0026amp;\u0026ldquo;みたいにできないのか。\nインストール済みのPowerShellバージョン。\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; $PSVersionTable Name Value ---- ----- PSVersion 5.1.19041.1023 PSEdition Desktop PSCompatibleVersions {1.0, 2.0, 3.0, 4.0...} BuildVersion 10.0.19041.1023 CLRVersion 4.0.30319.42000 WSManStackVersion 3.0 PSRemotingProtocolVersion 2.3 SerializationVersion 1.1.0.1 どうも、PowerShellバージョン6.0からジョブの実行にBackground演算子\u0026amp;が使える様になったみたい。\n（Background演算子 \u0026amp;）\nhttps://github.com/PowerShell/PowerShell/releases\nから最新の安定版をインストール。\n複数バージョンインストール可能みたい。\nバージョンアップしたPowerShellを起動。\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026gt; $PSVersionTable Name Value ---- ----- PSVersion 7.1.3 PSEdition Core GitCommitId 7.1.3 OS Microsoft Windows 10.0.19042 Platform Win32NT PSCompatibleVersions {1.0, 2.0, 3.0, 4.0…} PSRemotingProtocolVersion 2.3 SerializationVersion 1.1.0.1 WSManStackVersion 3.0 やってみた。\n1 2 3 4 5 \u0026gt; Get-Process -Name pwsh \u0026amp; Id Name PSJobTypeName State HasMoreData Location Command -- ---- ------------- ----- ----------- -------- ------- 1 Job1 BackgroundJob Running True localhost Microsoft.PowerShell.Man… これは、\n1 \u0026gt; Start-Job -ScriptBlock {Get-Process -Name pwsh} と等価。\nめっちゃ楽になった。\n","description":"","id":9,"section":"posts","tags":["PowerShell"],"title":"PowerShellで簡単バックグランド実行","uri":"https://tommylife88.github.io/posts/2021/2021-07-02-powershell-background/"},{"content":"Windowsのパフォーマンスモニタツールの一部カウンターが選択できなくなった。\nサーバー 2008 64 ビットまたは Windows Server 2008 R2 システムのパフォーマンス カウンター Windows手動で再構築するには、データベースが破損し再構築が必要になる場合がある、らしい。\nそこで、パフォーマンスモニタツールのカウンターを手動で復元する。\n以下のコマンドを実行すれば、ライブラリのDBを再構築して修復されるらしい。\n以下の実行は、自己責任でお願いします。\ncd C:\\Windows\\System32\rlodctr /R\rcd C:\\Windows\\SysWOW64\rlodctr /R ","description":"","id":10,"section":"posts","tags":["Windows","パフォーマンスカウンター"],"title":"パフォーマンスモニタ カウンターを手動で復元する方法","uri":"https://tommylife88.github.io/posts/2021/2021-07-01-restore-performance-counter/"},{"content":"AGL（Automotive Grade Linux）やってみた。\n#0_Getting_Started/1_Quickstart/Using_Ready_Made_Images/\nのx86 (Emulation and Hardware)をやってみた。\n試した環境 1 2 3 4 5 6 7 8 9 # Distro $ cat /etc/lsb-release DISTRIB_ID=Ubuntu DISTRIB_RELEASE=20.04 DISTRIB_CODENAME=focal DISTRIB_DESCRIPTION=\u0026#34;Ubuntu 20.04.2 LTS\u0026#34; # Kernel $ uname -a Linux XXX 5.8.0-53-generic #60~20.04.1-Ubuntu SMP Thu May 6 09:52:46 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux 手順 手順は、kvmという仮想化機構の利用を前提していて、ホストPCのCPUに仮想化支援機構が組み込まれているかによって実行手順・結果が変わってくるかも。\nそう古くないCPUでCore i3以上なら気にしなくて良いかと。\n確認する場合、/proc/cpuinfoにvmxというフラグが存在していればOKなはず。\n1 $ cat /proc/cpuinfo | grep vmx また、公式のやり方は、agl-demoの仮想イメージをqemuというアプリケーションで起動して、そこにVNC（vinagre）でリモートログインする方法。\nVNCを介さないやり方で実施してみた。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # homeフォルダに移動（特に決まりはない） $ cd ~ # エミュレータをインストール $ sudo apt install qemu # qemuからx86_64用Linuxカーネル起動するためのパッケージをインストール $ sudo apt install qemu-system-x86 # 作業フォルダ作成 \u0026amp; 作業フォルダに移動 $ mkdir agl-demo \u0026amp;\u0026amp; cd $_ # agl-demoの仮想イメージ取得 $ wget https://download.automotivelinux.org/AGL/snapshots/master/latest/qemux86-64/deploy/images/qemux86-64/agl-demo-platform-crosssdk-qemux86-64.ext4.xz # qemuのカーネルイメージ取得 $ wget https://download.automotivelinux.org/AGL/snapshots/master/latest/qemux86-64/deploy/images/qemux86-64/bzImage # agl-demoの仮想イメージを解凍 $ xz -v -d agl-demo-platform-crosssdk-qemux86-64.ext4.xz # agl-demoの仮想イメージを指定してqemuを起動 $ sudo qemu-system-x86_64 \\ -device virtio-net-pci,netdev=net0,mac=52:54:00:12:35:02 \\ -cpu kvm64 \\ -cpu qemu64,+ssse3,+sse4.1,+sse4.2,+popcnt \\ -enable-kvm \\ -m 2048 \\ -netdev user,id=net0,hostfwd=tcp::2222-:22 \\ -drive file=agl-demo-platform-crosssdk-qemux86-64.ext4,if=virtio,format=raw \\ -show-cursor \\ -usb \\ -vga virtio \\ -soundhw hda \\ -machine q35 \\ -serial mon:vc \\ -serial mon:stdio \\ -serial null \\ -kernel bzImage \\ -snapshot \\ -append \u0026#39;root=/dev/vda rw console=tty0 mem=2048M ip=dhcp oprofile.timer=1 console=ttyS0,115200n8 verbose fstab=no\u0026#39; しばらくするとdemo画面が表示された。\nスクリーンが横回転になっているのでこれは設定か何かかな。\nコンソールは以下（rootユーザー／パスワード無し）でログインできる。\n1 2 Automotive Grade Linux 11.91.0+snapshot qemux86-64 ttyS1 qemux86-64 login: root シャットダウンするときは\n1 qemux86-64 login: poweroff このとき、作業内容は消える。\n作業内容を保持したければ-snapshot \\を削除してqemuを起動すれば良さそう。\nWindouws on VirtualBoxも対応されている 試してはいないが、WindowsでもVirualBox上で動作可能みたい。\n#0_Getting_Started/1_Quickstart/Using_Ready_Made_Images/#2-virtual-box-emulation\n参考 Automotive Grade Linuxことはじめ ","description":"","id":11,"section":"posts","tags":["AGL","Ubuntu","Linux"],"title":"AGL（Automotive Grade Linux）ことはじめ","uri":"https://tommylife88.github.io/posts/2021/2021-06-15-agl-demo/"},{"content":"チームでVSCodeで開発するときに、「この拡張機能は入れておけ」ってあると思う。\nそんな時、VSCodeでお勧めの拡張機能に出す出さないを.vscode/extensions.jsonで管理できる。\nリポジトリで管理できるので便利。\nただし、拡張機能でも信頼できないものもあるので、チーム以外のリポジトリ（よくわからないもの）の.vscode/extensions.jsonはちゃんと拡張機能の評価を見てからにしましょう。\nこの機能は勝手にローカルにインストールするものでは無いのでそこは最終的に自己責任になる。\nhttps://qiita.com/Glavis/items/c3dac07e4bcf5c50db0a\n1 2 3 4 5 6 7 8 9 10 11 12 13 { // See https://go.microsoft.com/fwlink/?LinkId=827846 to learn about workspace recommendations. // Extension identifier format: ${publisher}.${name}. Example: vscode.csharp // List of extensions which should be recommended for users of this workspace. \u0026#34;recommendations\u0026#34;: [ \u0026#34;EditorConfig.EditorConfig\u0026#34;, \u0026#34;dbaeumer.vscode-eslint\u0026#34;, \u0026#34;esbenp.prettier-vscode\u0026#34;, ], // List of extensions recommended by VS Code that should not be recommended for users of this workspace. \u0026#34;unwantedRecommendations\u0026#34;: [\u0026#34;ms-vscode.vscode-typescript-tslint-plugin\u0026#34;] } ","description":"","id":12,"section":"posts","tags":["VSCode"],"title":"VSCodeでお勧めの拡張機能を共有する","uri":"https://tommylife88.github.io/posts/2021/2021-06-01-vscode-extensions/"},{"content":"制定日：2021年6月17日\n最終改定日：2021年6月17日\n運営者 About Me tommy\nsee GitHub README Social プライバシーポリシー 個人情報の利用目的 当ブログでは、お問い合わせや記事へのコメントの際、名前やメールアドレス等の個人情報を入力いただく場合がございます。\n取得した個人情報は、お問い合わせに対する回答や必要な情報を電子メールなどをでご連絡する場合に利用させていただくものであり、これらの目的以外では利用いたしません。\nアクセス解析ツールについて 当ブログでは、Googleによるアクセス解析ツール「Googleアナリティクス」を利用しています。このGoogleアナリティクスはトラフィックデータの収集のためにクッキー（Cookie）を使用しております。トラフィックデータは匿名で収集されており、個人を特定するものではありません。\n免責事項 当ブログからのリンクやバナーなどで移動したサイトで提供される情報、サービス等について一切の責任を負いません。\nまた当ブログのコンテンツ・情報について、できる限り正確な情報を提供するように努めておりますが、正確性や安全性を保証するものではありません。情報が古くなっていることもございます。\n当サイトに掲載された内容によって生じた損害等の一切の責任を負いかねますのでご了承ください。\n著作権について 当ブログで掲載している文章や画像などにつきましては、無断転載することを禁止します。\n当ブログは著作権や肖像権の侵害を目的としたものではありません。著作権や肖像権に関して問題がございましたら、お問い合わせフォームよりご連絡ください。迅速に対応いたします。\nリンクについて 当ブログは基本的にリンクフリーです。リンクを行う場合の許可や連絡は不要です。\nただし、インラインフレームの使用や画像の直リンクはご遠慮ください。\n","description":"Abount this site.","id":13,"section":"","tags":null,"title":"About","uri":"https://tommylife88.github.io/about/"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae.\nNote that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Inline Markdown In Table italics bold strikethrough code Code Blocks Code block with backticks html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Item First Sub-item Second Sub-item Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn: Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nThe above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","description":"Sample article showcasing basic Markdown syntax and formatting for HTML elements.","id":14,"section":"posts","tags":["markdown","demo"],"title":"Markdown Syntax Guide","uri":"https://tommylife88.github.io/posts/demo-markdown-syntax/"},{"content":"Code Syntax Highlighting Verify the following code blocks render as code blocks and highlight properly.\nMore about tuning syntax highlighting is the Hugo documentation.\nDiff 1 2 3 4 5 6 7 8 9 10 *** /path/to/original\t\u0026#39;\u0026#39;timestamp\u0026#39;\u0026#39; --- /path/to/new\t\u0026#39;\u0026#39;timestamp\u0026#39;\u0026#39; *************** *** 1 **** ! This is a line. --- 1 --- ! This is a replacement line. It is important to spell -removed line +new line *** /path/to/original\t\u0026#39;\u0026#39;timestamp\u0026#39;\u0026#39; --- /path/to/new\t\u0026#39;\u0026#39;timestamp\u0026#39;\u0026#39; *************** *** 1 **** ! This is a line. --- 1 --- ! This is a replacement line. It is important to spell -removed line +new line Makefile CC=gcc CFLAGS=-I. hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o -I. 1 2 3 4 5 CC=gcc CFLAGS=-I. hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o -I. JSON 1 2 3 {\u0026#34;employees\u0026#34;:[ {\u0026#34;firstName\u0026#34;:\u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;:\u0026#34;Doe\u0026#34;}, ]} Markdown 1 2 3 **bold** *italics* [link](www.example.com) JavaScript 1 document.write(\u0026#39;Hello, world!\u0026#39;); CSS 1 2 3 body { background-color: red; } Objective C 1 2 3 4 5 6 #import \u0026lt;stdio.h\u0026gt; int main (void) { printf (\u0026#34;Hello world!\\n\u0026#34;); } Python 1 print \u0026#34;Hello, world!\u0026#34; XML 1 2 3 4 5 \u0026lt;employees\u0026gt; \u0026lt;employee\u0026gt; \u0026lt;firstName\u0026gt;John\u0026lt;/firstName\u0026gt; \u0026lt;lastName\u0026gt;Doe\u0026lt;/lastName\u0026gt; \u0026lt;/employee\u0026gt; \u0026lt;/employees\u0026gt; Perl 1 print \u0026#34;Hello, World!\\n\u0026#34;; Bash 1 echo \u0026#34;Hello World\u0026#34; PHP 1 \u0026lt;?php echo \u0026#39;\u0026lt;p\u0026gt;Hello World\u0026lt;/p\u0026gt;\u0026#39;; ?\u0026gt; CoffeeScript 1 console.log(“Hello world!”); C# 1 2 3 4 5 6 7 8 using System; class Program { public static void Main(string[] args) { Console.WriteLine(\u0026#34;Hello, world!\u0026#34;); } } C++ 1 2 3 4 5 6 7 #include \u0026lt;iostream.h\u0026gt; main() { cout \u0026lt;\u0026lt; \u0026#34;Hello World!\u0026#34;; return 0; } SQL 1 2 SELECT column_name,column_name FROM table_name; Go 1 2 3 4 5 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello, 世界\u0026#34;) } Ruby 1 puts \u0026#34;Hello, world!\u0026#34; Java 1 2 3 4 5 6 7 8 9 10 11 12 import javax.swing.JFrame; //Importing class JFrame import javax.swing.JLabel; //Importing class JLabel public class HelloWorld { public static void main(String[] args) { JFrame frame = new JFrame(); //Creating frame frame.setTitle(\u0026#34;Hi!\u0026#34;); //Setting title frame frame.add(new JLabel(\u0026#34;Hello, world!\u0026#34;));//Adding text to frame frame.pack(); //Setting size to smallest frame.setLocationRelativeTo(null); //Centering frame frame.setVisible(true); //Showing frame } } Latex Equation 1 \\frac{d}{dx}\\left( \\int_{0}^{x} f(u)\\,du\\right)=f(x). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 import {x, y} as p from \u0026#39;point\u0026#39;; const ANSWER = 42; class Car extends Vehicle { constructor(speed, cost) { super(speed); var c = Symbol(\u0026#39;cost\u0026#39;); this[c] = cost; this.intro = `This is a car runs at ${speed}.`; } } for (let num of [1, 2, 3]) { console.log(num + 0b111110111); } function $initHighlight(block, flags) { try { if (block.className.search(/\\bno\\-highlight\\b/) != -1) return processBlock(block.function, true, 0x0F) + \u0026#39; class=\u0026#34;\u0026#34;\u0026#39;; } catch (e) { /* handle exception */ var e4x = \u0026lt;div\u0026gt;Example \u0026lt;p\u0026gt;1234\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt;; } for (var i = 0 / 2; i \u0026lt; classes.length; i++) { // \u0026#34;0 / 2\u0026#34; should not be parsed as regexp if (checkCondition(classes[i]) === undefined) return /\\d+[\\s/]/g; } console.log(Array.every(classes, Boolean)); } export $initHighlight; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello world\u0026lt;/title\u0026gt; \u0026lt;link href=\u0026#39;http://fonts.googleapis.com/css?family=Roboto:400,400italic,700,700italic\u0026#39; rel=\u0026#39;stylesheet\u0026#39; type=\u0026#39;text/css\u0026#39;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;index.css\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;//cdnjs.cloudflare.com/ajax/libs/less.js/2.5.1/less.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;vendor/prism.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;examples.bundle.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 /********************************************************* * General */ pre[class*=\u0026#34;language-\u0026#34;], code { color: #5c6e74; font-size: 13px; text-shadow: none; font-family: Consolas, Monaco, \u0026#39;Andale Mono\u0026#39;, \u0026#39;Ubuntu Mono\u0026#39;, monospace; direction: ltr; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; line-height: 1.5; tab-size: 4; hyphens: none; } pre[class*=\u0026#34;language-\u0026#34;]::selection, code::selection { text-shadow: none; background: #b3d4fc; } @media print { pre[class*=\u0026#34;language-\u0026#34;], code { text-shadow: none; } } pre[class*=\u0026#34;language-\u0026#34;] { padding: 1em; margin: .5em 0; overflow: auto; background: #f8f5ec; } :not(pre) \u0026gt; code { padding: .1em .3em; border-radius: .3em; color: #db4c69; background: #f9f2f4; } ","description":"Syntax highlighting test","id":15,"section":"posts","tags":["demo"],"title":"Syntax highlighting","uri":"https://tommylife88.github.io/posts/demo-syntax-highlight/"},{"content":"Jenkinsサーバーのビルド環境をクリーンに保ちたいのでDockerコンテナでCIを回したい。\nその環境作成メモ。\nっていうか、これやるなら、GitLab CI/CD、GitHub Actionsの方が簡単だけど。（Jesnkinsおじさんとはもうおさらば）\n要件など Docker outside of Docker（DooD）したい。\nJenkins本体はDockerコンテナ上で実行される Jenkinsのビルドジョブ時のDocker操作はホストに接続され、ホスト環境にコンテナを作成する（DooD） セキュリティの観点から、Dockerを操作するユーザーをroot以外（jenkins）で作成する dockerグループをホスト側のDockerグループIDで作成する jenkinsユーザーをdockerグループに所属させ、ホストのDockerへの操作権限を与える ホスト環境 JenkinsをDockerするホストの環境。\n1 2 3 4 5 6 7 8 $ uname -srv Linux 5.8.0-40-generic #45~20.04.1-Ubuntu SMP Fri Jan 15 11:35:04 UTC 2021 $ cat /etc/lsb-release DISTRIB_ID=Ubuntu DISTRIB_RELEASE=20.04 DISTRIB_CODENAME=focal DISTRIB_DESCRIPTION=\u0026#34;Ubuntu 20.04.2 LTS\u0026#34; dockerコンテナのイメージ一覧。\n後でJenkins上のビルドジョブからdocker imagesして同じ結果が表示されればOK。\n1 2 3 4 5 6 $ docker --version Docker version 19.03.8, build afacb8b7f0 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE gcc latest e4aa98dc41ec 5 weeks ago 1.19GB docker/getting-started latest 3c156928aeec 10 months ago 24.8MB 構築してみた 構築した環境はGitHubにあげています。\nhttps://github.com/tommylife88/jenkins-dood\n簡単な解説 ホストのDockerグループIDをCOMPOSE内で使用するための環境変数を記載した設定ファイル。\n1 DOCKER_GROUP_ID=1001 docker-composeの設定ファイル。\nポートフォワードやJAVA_OPTSは好きなようにカスタマイズして良いが、肝はvolumesで/var/run/docker.sock:/var/run/docker.sockしているところ。このマウントを行うことでJenkinsからホストのDockerに接続できる。\ndocker-composeの設定まわりは、公式見よう。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 version: \u0026#39;2\u0026#39; services: jenkins: container_name: \u0026#34;jenkins-dood\u0026#34; build: context: ./ args: - DOCKER_GROUP_ID_HOST=${DOCKER_GROUP_ID} environment: - JAVA_OPTS=-Duser.timezone=Asia/Tokyo -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8 ports: - 8080:8080 volumes: - ./jenkins-data:/var/jenkins_home - /var/run/docker.sock:/var/run/docker.sock # mount docker.sock on host Jenkins DooD環境構築用のDockerfile。特に難しいことはしていないはず。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 FROM jenkins/jenkins:lts USER root # add jenkins user RUN mkdir /home/jenkins \u0026amp;\u0026amp; chown jenkins:jenkins /home/jenkins \u0026amp;\u0026amp; usermod -d /home/jenkins jenkins # add docker group ARG DOCKER_GROUP_ID_HOST RUN groupadd -g ${DOCKER_GROUP_ID_HOST} docker \u0026amp;\u0026amp; usermod -aG docker jenkins # install docker, docker-compose ENV DOCKER_VERSION 20.10.0 RUN curl -fL -o docker.tgz \u0026#34;https://download.docker.com/linux/static/test/x86_64/docker-$DOCKER_VERSION.tgz\u0026#34; \u0026amp;\u0026amp; \\ tar --strip-component=1 -xvaf docker.tgz -C /usr/bin ENV DOCKER_COMPOSE_VERSION 1.28.4 RUN curl -L https://github.com/docker/compose/releases/download/${DOCKER_COMPOSE_VERSION}/docker-compose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose \u0026amp;\u0026amp; chmod +x /usr/local/bin/docker-compose USER jenkins 動作確認 Jenkinsのビルドジョブを作成、シェルスクリプトでdocker imagesしてみた結果。\n最後のdocker imagesでホストのDocker環境に接続されている様子が分かる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 Running as SYSTEM Building in workspace /var/jenkins_home/workspace/dood [dood] $ /bin/sh -xe /tmp/jenkins3072304799133685752.sh + docker --version Docker version 20.10.0, build 7287ab3 + docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ + docker images REPOSITORY TAG IMAGE ID CREATED SIZE jenkins-dood_jenkins latest 4b69f7a5d92f About an hour ago 877MB jenkins/jenkins lts 3f6389c017cc 13 days ago 566MB gcc latest e4aa98dc41ec 6 weeks ago 1.19GB docker/getting-started latest 3c156928aeec 10 months ago 24.8MB hello-world latest bf756fb1ae65 13 months ago 13.3kB Finished: SUCCESS Docker Pipeline プラグイン Docker Pipelineプラグインを使っても同じ。\nJenkinsのパイプラインジョブで以下のような構成のパイプラインを設定する。\n（ホストにあるgccイメージからコンテナを作成しバージョンを表示するだけ）\npipeline { agent { docker { image \u0026#39;gcc\u0026#39; } } stages { stage(\u0026#39;Test\u0026#39;) { steps { sh \u0026#39;gcc --version\u0026#39; } } } } 実行した結果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 Running in Durability level: MAX_SURVIVABILITY [Pipeline] Start of Pipeline [Pipeline] node Running on Jenkins in /var/jenkins_home/workspace/dood-on-pipeline [Pipeline] { [Pipeline] isUnix [Pipeline] sh + docker inspect -f . gcc . [Pipeline] withDockerContainer Jenkins seems to be running inside container 088af532f126104ee3d55483f61105735e282b73383c8d1040a97a9b6300f723 $ docker run -t -d -u 1000:1000 -w /var/jenkins_home/workspace/dood-on-pipeline --volumes-from 088af532f126104ee3d55483f61105735e282b73383c8d1040a97a9b6300f723 -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** gcc cat $ docker top aa54c31546bb4b3a7b5876ce9145c1ee80eef828c3ec0659cb1a95410568ef28 -eo pid,comm [Pipeline] { [Pipeline] stage [Pipeline] { (Test) [Pipeline] sh + gcc --version gcc (GCC) 10.2.0 Copyright (C) 2020 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. [Pipeline] } [Pipeline] // stage [Pipeline] } $ docker stop --time=1 aa54c31546bb4b3a7b5876ce9145c1ee80eef828c3ec0659cb1a95410568ef28 $ docker rm -f aa54c31546bb4b3a7b5876ce9145c1ee80eef828c3ec0659cb1a95410568ef28 [Pipeline] // withDockerContainer [Pipeline] } [Pipeline] // node [Pipeline] End of Pipeline Finished: SUCCESS 問題なさそう。\nただ、GitLab CI/CDとかに慣れると、Jenkinsのパイプライン設定はとっつきにくい。\n","description":"","id":16,"section":"posts","tags":["Jenkins","Docker"],"title":"Docker上のJenkinsからホストのDockerを使う（DooD）","uri":"https://tommylife88.github.io/posts/2020/2020-08-29-jenkins-dood/"},{"content":"NTPでサーバーの時刻合わせ【Ubuntu 18.04】 NTPは「Network Time Protocol」の略で、ネットワーク上でクライアントがサーバーに対して時刻を問い合わせるためのプロトコルです。\nNTPによって時刻が正確に保たれるので、保守面からもサーバーにインストールしておいて損はないでしょう。\nUbuntuであればインストールから設定まで簡単に導入出来ます。\n1 2 $ sudo apt -y install ntp $ sudo vi /etc/ntp.conf /etc/ntp.confに自身のタイムゾーンのNTPサーバーを追記します。デフォルトはコメントアウトします。\n/etc/ntp.conf\n1 2 3 4 5 6 7 8 9 10 11 12 #pool 0.ubuntu.pool.ntp.org iburst #pool 1.ubuntu.pool.ntp.org iburst #pool 2.ubuntu.pool.ntp.org iburst #pool 3.ubuntu.pool.ntp.org iburst # Use Ubuntu\u0026#39;s ntp server as a fallback. #pool ntp.ubuntu.com server ntp.nict.jp iburst server ntp1.jst.mfeed.ad.jp iburst server ntp2.jst.mfeed.ad.jp iburst server ntp3.jst.mfeed.ad.jp iburst NTPサーバーは、\n立行政法人情報通信研究機構(NICT)の公開NTPサーバー インターネットマルチフィード(MFEED) 時刻情報提供サービス for Public としました。\n正確な時間を得るためには「サーバー間の物理的な距離」も大事です。日本国内の有名どころを選んでみました。\nNTPを再起動して動作確認します。\n1 2 3 4 5 6 7 8 $ sudo systemctl restart ntp $ ntpq -p remote refid st t when poll reach delay offset jitter ============================================================================== *ntp-b2.nict.go. .NICT. 1 u 21 64 3 23.464 2.820 21.957 +ntp1.jst.mfeed. 133.243.236.17 2 u 22 64 3 24.403 1.069 3.885 +ntp2.jst.mfeed. 133.243.236.17 2 u 17 64 3 26.187 2.418 3.868 +ntp3.jst.mfeed. 133.243.236.17 2 u 21 64 3 24.008 3.610 4.740 左端の「*」は現在同期を行っているサーバー、「+」は次に同期行う候補のサーバーを表しています。\n時刻同期が安定してくると、「poll」で表示される間隔が長くなっていきます。最大1024秒で時刻問い合わせを行うようになりますので、勝手にシステムへの負荷が少なくなるようになっていきます。\n","description":"","id":17,"section":"posts","tags":["ntp","Ubuntu"],"title":"NTPでサーバーの時刻合わせ【Ubuntu 18.04】","uri":"https://tommylife88.github.io/posts/2020/2020-02-09-ntp-on-ubuntu1804/"},{"content":"Redmine 4.0をUbuntu 18.04 LTS Serverにインストールする手順\nで構築したRedmineをアップデート／バージョンアップする。\nアップデート準備 まずは、 http://redmine.jp/redmine_today/ からRedmineの最新情報を確認しておく。\n必ず、\n最新バージョンが動作環境を満たしていることも確認しておく アップデート作業に入る前に必ずデータベース、およびアップロードしているファイルのバックアップをとっておく こと。\nアップデートは基本的に、 http://guide.redmine.jp/RedmineUpgrade/ の公式の手順に従うだけ。\nアップデート RedmineはSVNリポジトリからチェックアウトしてる前提。\n1 2 3 4 5 6 7 8 9 10 11 12 13 # Redmineのインストールディレクトに移動（自分の環境に合わせて） cd /var/www/redmine # SVNチェックアウトのアップグレード sudo -u www-data svn update # 必要なgemを更新 sudo -u www-data bundle update # データベースの更新 sudo -u www-data RAILS_ENV=production bundle exec rake db:migrate sudo -u www-data RAILS_ENV=production bundle exec rake redmine:plugins:migrate # キャッシュのクリア sudo -u www-data RAILS_ENV=production bundle exec rake tmp:cache:clear # apacheの再起動 sudo systemctl restart apache2 最後に、Redmineサイトに管理者権限でログインして「管理」→「ロールと権限」画面を開き、Redmineのバージョンを確認して、一通り動作確認を行う。\n","description":"","id":18,"section":"posts","tags":["Redmine","Ubuntu"],"title":"Redmineをアップデートする手順（Ubuntu 18.04 LTS Server）","uri":"https://tommylife88.github.io/posts/2020/2020-01-20-update-redmine-on-ubuntu1804/"},{"content":"最小構成でインストールしたUbuntu 18.04.1 LTS ServerにRedmine 4.0をインストールする手順を残しておく。\nUbuntuのLTSの最新は20.04だが、Redmineの依存ライブラリ（Ruby等）がUbuntuの標準パッケージのものは新しすぎて環境整備が大変。\n現時点では18.04が楽と思われる。（Redmineのバージョンアップに期待） 要件は公式を確認しておこう。\nhttp://guide.redmine.jp/RedmineInstall/\nサーバー環境 Redmine以外は基本的にOS標準のパッケージで足りていることを想定しています。\nOS：Ubuntu 18.04.1 LTS Server Redmine：Redmine 4.0 stable データベース：MySQL 5.7.26 Webサーバー：Apache 2.4.18 (PassengerでRails実行) Ruby：2.5.1 OSの設定 OSインストール直後、パッケージの最新化、日本語設定。\n1 2 3 4 5 6 sudo locale-gen ja_JP.UTF-8 sudo update-locale LANG=ja_JP.UTF-8 sudo dpkg-reconfigure tzdata sudo apt update sudo apt upgrade -y sudo apt-get dist-upgrade 必要なパッケージをインストール 一応、Redmine 4.0に必要なRubyがOS標準で入手可能か確認する。公式によるとRedmine 4.0の場合、Ruby 2.2.2 以降、Rails 5.2が必須。\n1 2 3 4 5 6 sudo apt update apt-cache madison ruby #ruby | 1:2.5.1 | http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages sudo apt install ruby-dev ruby bundler apache2 libapache2-mod-passenger imagemagick libmagick++-dev subversion mysql-server libmysqlclient-dev #ruby -v ruby 2.5.1p57 (2018-03-29 revision 63029) [x86_64-linux-gnu] MySQLの設定 文字コードの設定、ユーザーとデータベースの設定。\n1 2 sudo vi /etc/mysql/conf.d/redmine.cnf sudo chmod 644 /etc/mysql/conf.d/redmine.cnf redmine.cnf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [mysqld] innodb_file_format = Barracuda innodb_file_per_table = 1 innodb_large_prefix = 1 character-set-server = utf8mb4 skip-character-set-client-handshake collation-server = utf8mb4_general_ci init-connect = SET NAMES utf8mb4 [mysql] default-character-set = utf8mb4 [client] default-character-set = utf8mb4 [mysqldump] default-character-set = utf8mb4 mysql_secure_installationでrootユーザーのパスワード等、MySQLをインストールする。\n1 2 3 sudo mysql_secure_installation sudo service mysql restart sudo mysql -uroot -p ここからMySQLのコマンドプロンプト上で。\nRedmine用のデータベースをredmineという名前で作成し、localhostのredmineというユーザー(パスワードmy_password)にredmineデータベースへのすべての権限を与えている。\n1 2 3 CREATE DATABASE redmine CHARACTER SET utf8mb4; CREATE USER \u0026#39;redmine\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;my_password\u0026#39;; GRANT ALL PRIVILEGES ON redmine.* TO \u0026#39;redmine\u0026#39;@\u0026#39;localhost\u0026#39;; Redmineの設定 Redmineアプリケーション実行用のフォルダを作成し、オーナーとグループをwww-dataに設定する。(apacheプロセスがRedmine環境のユーザーになるため、apacheプロセスへのアクセス権を与える)\n1 2 3 4 sudo mkdir -p /var/www/redmine sudo chown www-data:www-data /var/www/redmine sudo -u www-data svn co http://svn.redmine.org/redmine/branches/4.0-stable /var/www/redmine sudo -u www-data vi /var/www/redmine/config/database.yml データベースの設定ファイルconfig/database.ymlを以下のように設定する。\n1 2 3 4 5 6 7 8 9 10 11 production: adapter: mysql2 database: redmine host: localhost username: redmine password: \u0026#34;my_redmine\u0026#34; encoding: utf8mb4 charset: utf8mb4 collation: utf8mb4_general_ci pool: \u0026lt;%= ENV.fetch(\u0026#34;RAILS_MAX_THREADS\u0026#34;) { 5 } %\u0026gt; socket: /var/run/mysqld/mysqld.sock utf8mb4の有効化。\n1 sudo -u www-data vi /var/www/redmine/config/initializers/utf8mb4.rb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 module Utf8mb4 def create_table(table_name, options = {}) table_options = options.merge(options: \u0026#39;ENGINE=InnoDB ROW_FORMAT=DYNAMIC\u0026#39;) super(table_name, table_options) do |td| yield td if block_given? end end end ActiveSupport.on_load :active_record do module ActiveRecord::ConnectionAdapters class AbstractMysqlAdapter prepend Utf8mb4 end end end Redmineのインストール RubyGemの依存解決と、データベース構築など。\n1 2 3 4 5 6 7 8 sudo chown -R www-data:www-data /var/www/redmine cd /var/www/redmine/ sudo gem update bundler sudo apt-get remove bundler # apt の bundler は要らなかった sudo -u www-data bundle install --without development test postgresql sqlite --path vendor/bundle sudo -u www-data bundle exec rake generate_secret_token sudo -u www-data RAILS_ENV=production bundle exec rake db:migrate sudo -u www-data RAILS_ENV=production REDMINE_LANG=ja bundle exec rake redmine:load_default_data Apache連携 RedmineとApcheの連携。PassengerはApache上でRailsアプリを動かすもの。\nPassenger設定 1 sudo vi /etc/apache2/mods-available/passenger.conf \u0026lt;IfModule mod_passenger.c\u0026gt; PassengerRoot /usr/lib/ruby/vendor_ruby/phusion_passenger/locations.ini PassengerDefaultRuby /usr/bin/ruby PassengerPreStart http://127.0.0.1:80/redmine/ \u0026lt;/IfModule\u0026gt; IPアドレスやポートは適宜変更する。\nRedmine設定 1 sudo vi /etc/apache2/sites-available/redmine.conf /etc/apache2/sites-available/redmine.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 listen 80 \u0026lt;VirtualHost *:80\u0026gt; ServerName redmine.com ServerAdmin redmine@redmine.com DocumentRoot /var/www/html RackBaseURI /redmine PassengerHighPerformance on \u0026lt;Directory /var/www/redmine/public\u0026gt; # Require ip ::1 127. 192.168. AllowOverride None Options None \u0026lt;/Directory\u0026gt; ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined \u0026lt;/VirtualHost\u0026gt; RailsEnv production RailsBaseURI /redmine IPアドレスやポートは適宜変更する。\n1 2 sudo ln -s /var/www/redmine/public /var/www/html/redmine sudo a2ensite redmine 起動！ Apacheを再起動して運用開始！！\n1 sudo systemctl reload apache2 ブラウザからhttp://127.0.0.1:80/redmine/にアクセスしてRedmineのページが表示されれば作業完了です！\n","description":"","id":19,"section":"posts","tags":["Redmine","Ubuntu"],"title":"Redmine 4.0をUbuntu 18.04 LTS Serverにインストールする手順","uri":"https://tommylife88.github.io/posts/2020/2020-01-15-install-redmine-to-ubuntu1804/"},{"content":"Makefileって作るときはいろいろ調べながら作るけど、一度作るとそれ以上触ることないので、よく忘れる。備忘録も兼ねてテンプレとして残しておきます。\n全ての環境での動作を保証するものではない。使用する際は、環境に合わせて使う。 成果物はGitHubにプッシュ済み。\nhttps://github.com/tommylife88/makefile-template.git\nMakefileテンプレート 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 # Makefile Template. # . # |-- Makefile (This file) # |-- build # | `-- target file. # |-- obj # `-- object files. # |-- include # | `-- header files. # `-- source # `-- source files. # Variables ## Directory defines BUILDDIR = ./build OBJDIR = $(BUILDDIR)/obj SRCDIR = ./source INCDIRS = ./include LIBDIRS = #-L ## Target name TARGET = $(BUILDDIR)/a.out ## Compiler options CC = gcc CFLAGS = -O2 -Wall CXX = g++ CXXFLAGS = -O2 -Wall LDFLAGS = SRCS := $(shell find $(SRCDIR) -name *.cpp -or -name *.c -or -name *.s) OBJS := $(SRCS:%=$(OBJDIR)/%.o) DEPS := $(OBJS:.o=.d) LIBS = #-lboost_system -lboost_thread INCLUDE := $(shell find $(INCDIRS) -type d) INCLUDE := $(addprefix -I,$(INCLUDE)) CPPFLAGS := $(INCLUDE) -MMD -MP LDFLAGS += $(LIBDIRS) $(LIBS) # Target default: make all all: $(TARGET) $(TARGET): $(OBJS) $(CXX) -o $@ $^ $(LDFLAGS) # assembly $(OBJDIR)/%.s.o: %.s $(MKDIR_P) $(dir $@) $(AS) $(ASFLAGS) -c $\u0026lt; -o $@ # c source $(OBJDIR)/%.c.o: %.c $(MKDIR_P) $(dir $@) $(CC) $(CPPFLAGS) $(CFLAGS) -c $\u0026lt; -o $@ # c++ source $(OBJDIR)/%.cpp.o: %.cpp $(MKDIR_P) $(dir $@) $(CXX) $(CPPFLAGS) $(CXXFLAGS) -c $\u0026lt; -o $@ .PHONY: all clean rebuild clean: $(RM) -r $(BUILDDIR) rebuild: make clean \u0026amp;\u0026amp; make -include $(DEPS) MKDIR_P = mkdir -p ポイント out-of-source ビルド 本Makefileはout-of-sourceビルドとしています。buildディレクトリ直下に実行ファイル、build/objディレクトリにオブジェクトファイルと依存関係リストファイルを生成しています。\nout-of-sourceビルドする利点として、\nソースディレクトリが汚れない cleanするときに楽 があります。\nヘッダファイルの依存関係の解決（-MMD、-MPオプション） Makefileの依存関係の記述の仕方によっては、ヘッダーファイルのみを編集した場合で、そのヘッダーファイルをインクルードしているソースファイルがコンパイルされないことがあります。しかもたちが悪いことにビルドが通ってしまう可能性もあるため致命的な欠陥になりかねないのです。\nこれは-MMDや-MPオプションで解決できます。\n-MMD … 依存関係にあるファイルリストを拡張子.dのファイルに保存しコンパイルを行う。 -MP … ヘッダーファイルを削除した場合、もともと依存関係にあるファイルはそのヘッダーファイルを探してしまいコンパイルが通らなくなる。本オプションは偽のターゲットを定義することで、削除されたはずのヘッダーファイルを探しても大丈夫なようにしてあげる。 1 2 3 4 5 6 7 8 9 （省略） SRCS := $(shell find $(SRCDIR) -name *.cpp -or -name *.c -or -name *.s) OBJS := $(SRCS:%=$(OBJDIR)/%.o) DEPS := $(OBJS:.o=.d) （省略） CPPFLAGS := $(INCLUDE) -MMD -MP （省略） -include $(DEPS) （省略） 本MakefileではDEPS変数に全オブジェクトファイルの依存ファイルである拡張子.dファイルを生成し、-include $(DEPS)で依存関係の解消を行っています。\n","description":"","id":20,"section":"posts","tags":["makefile","gcc"],"title":"Makefileテンプレート作った","uri":"https://tommylife88.github.io/posts/2019/2019-12-01-makefile-template/"},{"content":"Dockerレジストリを経由せず、Dockerイメージをファイルとして配布したい。\nコンテナをtarファイル化 docker export使う。\n1 $ docker export \u0026lt;container id\u0026gt; \u0026gt; docker_archive.tar tarファイルからDockerイメージを作成 docker import使う。\n1 $ cat docker_archive.tar | docker import - hoge:latest コンテナ起動 1 $ docker run -it hoge:latest ","description":"","id":21,"section":"posts","tags":["Docker"],"title":"Dockerコンテナをエクスポート／インポートする","uri":"https://tommylife88.github.io/posts/2019/2019-11-22-export-docker-container/"},{"content":"dockerで起動しっぱなしのコンテナのログがディスクを圧迫していたので、ログを消去する方法と、ついでにログのローテーション設定を行った。\ndocker-composeでも同じ。\nログのクリア方法 まずは手動でログをクリアする方法から。\nデフォルトのロギングドライバは「json-file」 1 2 $ docker info | grep Logging Logging Driver: json-file json-fileはコンテナの標準出力と標準エラーを/var/lib/docker/containers/[container-id]/[container-id]-json.log（環境に依存するかも）に出力するため起動しっぱなしだとディスクを圧迫する。\nログを手動で消去する 名前は適宜置き換えて。 まず起動しているコンテナの一覧を表示する。\n1 2 3 4 5 $ docker-compose ps Name Command State Ports --------------------------------------------------------------------------------------- XXXX_app_1 /docker-entrypoint.sh dock ... Up 0.0.0.0:3000-\u0026gt;3000/tcp … ログを吐いてみる。\n$ docker logs XXXX_app_1 #大量のログが・・ コンテナのログの保存場所を調べる。\n1 2 3 $ docker inspect XXXX_app_1 | grep -i log \u0026#34;LogPath\u0026#34;: \u0026#34;/var/lib/docker/containers/bef1e7aa9c237a34a9ea08dfd5253c3621915bed2cfd65f7985580998607beb1/bef1e7aa9c237a34a9ea08dfd5253c3621915bed2cfd65f7985580998607beb1-json.log\u0026#34;, \u0026#34;LogConfig\u0026#34;: { （消去して問題ないかを確認した上で）ログを消去する。\nroot権限が必要かも。\n1 $ truncate -s 0 /var/lib/docker/containers/bef1e7aa9c237a34a9ea08dfd5253c3621915bed2cfd65f7985580998607beb1/bef1e7aa9c237a34a9ea08dfd5253c3621915bed2cfd65f7985580998607beb1-json.log というか、docker logs cleanてきなコマンドはないのかね。\nログのローテート設定 次にローテーションさせる。\nグローバル設定で行う場合 dockerデーモンの設定ファイル/etc/docker/daemon.json（デフォルトの場所）にロギングドライバのオプションを書く。ファイルが無い場合は新規作成する。\nhttp://docs.docker.jp/engine/reference/commandline/dockerd.html#daemon-configuration-file\n1 2 3 4 5 $ cat /etc/docker/daemon.json { \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: {\u0026#34;max-size\u0026#34;: \u0026#34;10m\u0026#34;, \u0026#34;max-file\u0026#34;: \u0026#34;3\u0026#34;} } dockerデーモンを再起動する。\n1 2 3 $ docker-compose stop $ systemctl restart docker $ docker-compose start 設定は新しく作成したコンテナから適用される。 （構築済みのコンテナには反映されません）\ndocker run オプションで行う場合 docker runコマンドのオプションとして指定できる。\nhttp://docs.docker.jp/engine/reference/logging/overview.html#json\n1 2 --log-opt max-size=[0-9+][k|m|g] --log-opt max-file=[0-9] 1 2 $ docker run -d --log-opt max-size=1k --log-opt max-file=10 $ docker start --log-opt max-size=100m --log-opt max-file=10 docker-compose.yml で設定する場合 docker-composeでは\n1 2 3 4 5 6 7 8 9 10 11 12 mongo: image: mongo:3.4 volumes: - mongo_configdb:/data/configdb - mongo_db:/data/db # add ↓↓↓ logging: driver: \u0026#34;json-file\u0026#34; # defaults if not specified options: max-size: \u0026#34;10m\u0026#34; max-file: \u0026#34;3\u0026#34; # add ↑↑↑ と書くと設定される。\n構築済みのコンテナの場合は、docker-compose upでコンテナの再構築が必要。\n","description":"","id":22,"section":"posts","tags":["Docker"],"title":"Dockerコンテナのログのクリア方法とローテーション設定","uri":"https://tommylife88.github.io/posts/2019/2019-11-20-docker-log-rotation/"},{"content":"LPIC-3（304：仮想化とハイアベイラビリティ）試験を受けて、無事一発合格してきました。記念してどう対策してきたかを記事にしたいと思います。\nLPIC-2（201,202）は合格済みです。\nLPICを取ろうと思った経緯など 勉強を始める前の僕のLinuxのスキルとしては、↓こんな感じ。\nLinuxコマンドを使うことができる（調べ方を知っているといったほうがいいでしょうか） 中規模なLinuxサーバーを構築できる 仮想サーバーで何かできる はまってもググってなんとかすることができる 全部独学、ネット記事の見様見真似が多い たまたまLPICというLinux技術者認定資格があることを知って、これまで独学でやってきたことがレベル3の出題範囲をカバーしてたので、これだったら楽に取れるんじゃね？と思ったのがきっかけです。\nモチベーションを維持できたのは、ぶっちゃけ、会社の資格報奨制度にLPICレベル1～3が対象としてあったから、というのが本音です。\n実際に受験してみて思ったこと 正直、仮想サーバーでいろいろ遊んでいた身としては、LPIC-2より簡単でした。\n勉強期間でいうと、だいたい1日30分～1時間程度で2.5週間かけました。LPIC-2だと倍以上かけているので、凄く楽に感じました。\nLPICとは 「Linux Professional Institute Certification」の略。「エルピック」と発音するらしいです。\nLinuxのスキルを証明するための「中立公正な」資格試験であり、世界標準な資格になっているようです。\n【注意】LPICとLinuCは別物！ 同じLinux技術者認定資格として「LinuC」もあるので注意が必要。主催している団体が違って、LPICは「 LPI日本支部 」、LinuCは「LPI-Japan」となっています。\nIT資格といえば LinuC | Linux技術者認定試験 リナック | LPI-Japan\nもともとLPICだけだったにも関わらずLinuCができた経緯は良く分かりませんが（大人の事情があることは容易に想像できますが）、非常に紛らわしい。\nどうもLinuCは日本にローカライズされた資格を目指しているらしいけど、「Linux」というグローバルな技術要素を何故日本用にローカライズする必要があるのか、甚だ疑問です。\nどっちを取るかは、会社の報償制度やグローバルな資格が欲しいか、といった観点で判断すればいいでしょう。\nLPIC-3 LPIC-3は、エンタープライズレベルのLinuxプロフェッショナル向けに設計されており、業界内でプロフェッショナルな、ディストリビューションに中立なLinux認定レベルを誇っています。\nLPIC-3認定を受けるためには？\nLPIC-1やLPIC-2と異なり、1つ合格するだけでLPIC-3の認定を受けることができます。\nLPIC-3 300：Linux Enterprise Professional 混在環境 LPIC-3 303：Linux Enterprise Professional セキュリティ LPIC-3 304：Linux Enterprise Professional 仮想化とハイアベイラビリティ もちろん、LPIC-2認定を受けていることが条件です。ただし、受験する順番は決められておらず、例えば「 304 →201→202」と受験しても問題ありません。\n価格が改定され30,000円→15,000円になった 実は2019年5月1日よりLPIC-3の受験料が15,000円に改定されました。これは非常にうれしいことですね。\nてか30,000円って高すぎるよ。\nLPIC-3 304の範囲 公式ホームページから確認できます。\n出題範囲はそこまで広くありませんが、概念を問われる問題が多いので、丸暗記ではなく、基本をしっかりと身に着けておきたいところです。\n受験の準備 受験はCBT方式です。自分で試験日、試験会場を予約する必要があります。\nLPICにアカウント登録する まずは、 https://www.lpi.org/ja/ からアカウントを作りましょう。\n試験日程、試験会場を予約する 受験申込はピアソンVUEから行います。 https://www.pearsonvue.co.jp/ からアカウントを作って、近くの試験場を選択して受験申込をしてしまいましょう。\n勉強法 始めは参考書で一通り覚えて、Ping-tで周回するイメージです。仮想化に関しては実際にやってみて覚えることは出来ますが、 高可用性に関しては環境構築が難しくほぼ丸暗記しました。\n参考書 所謂「黒本」ってやつです。本番の問題も黒本の演習問題と同じような傾向でしたので、対策としてはこれ一冊でも十分過ぎるくらいかもしれません。\nPing-t ほぼ Ping-t で勉強してました。304のコンテンツ利用は有料になっています。6ヵ月利用で5,000円程度だったかと思います。\nhttps://ping-t.com/\n受験までに全ての問題を金にしました。\n周回していると問題を見るだけで答えが分かってしまうので本質的ではありません。そこは解説を隅まで理解するようにして、注意しながらやってました。\n高可用性に関しては丸暗記した LPIC-1、LPIC-2までは実際にLinux環境を構築してコマンドをたたいて体で覚えることはできました。\nLPIC-3 304に関して、仮想化に関してはホストOSがLinuxな環境があれば実際にやってみることが出来るでしょう。ただ、 高可用性に関しては環境構築が難しかったので、試験と割り切って丸暗記しました。\n「試験日」を決めて取り掛かること 受験はCBT方式なので、受験日を自分で決めることができます。 これがメリットでもあり、デメリットでもあります。\n受験日はこの日と決めることで、メリハリある勉強が出来ると思います。\nではでは、頑張ってください。\n","description":"","id":23,"section":"posts","tags":["Linux","LPIC","LPIC-3"],"title":"「祝★LPIC-3認定」LPIC304に合格するために必要なこと","uri":"https://tommylife88.github.io/posts/2019/2019-08-03-linux-lpic3/"},{"content":"LPIC-2（201、202）試験を受けて、無事一発合格してきました。記念してこれまでの経緯やどう対策してきたかを記事にしたいと思います。\nLPICを取ろうと思った経緯など 勉強を始める前の僕のLinuxのスキルとしては、↓こんな感じ。\nLinuxコマンドを使うことができる（調べ方を知っているといったほうがいいでしょうか） 中規模なLinuxサーバーを構築できる 仮想サーバーで何かできる はまってもググってなんとかすることができる 全部独学、ネット記事の見様見真似が多い たまたまLPICというLinux技術者認定資格があることを知って、これまで独学でやってきたことがレベル3の出題範囲をカバーしてたので、これだったら楽に取れるんじゃね？と思ったのがきっかけです。\nLinux Professional Institute\nモチベーションを維持できたのは、ぶっちゃけ、会社の資格報奨制度にLPICレベル1～3が対象としてあったから、というのが本音です。\n実際に受験してみて思ったこと 正直、レベル1～3の中でLPIC-2の2つ（201、202）が一番きつかったです。一つ一つの章の難易度が高いうえに、細かなオプションまで問われるので、30歳超えた頭には暗記は苦痛でしかなかったです・・。\n普通Linuxコマンドのオプションなんてmanやコマンドヘルプに頼りますからね。エンジニアとしては、そういう手段だけを知っていればいいはずです。\nあと、受験料が1つ15,000円は高い！このプレッシャーは半端なかったです。\nLPICとは 「Linux Professional Institute Certification」の略。「エルピック」と発音するらしいです。\nLinuxのスキルを証明するための「中立公正な」資格試験であり、世界標準な資格になっているようです。\n【注意】LPICとLinuCは別物！ 同じLinux技術者認定資格として「LinuC」もあるので注意が必要。主催している団体が違って、LPICは「 LPI日本支部 」、LinuCは「LPI-Japan」となっています。\nIT資格といえば LinuC | Linux技術者認定試験 リナック | LPI-Japan\nもともとLPICだけだったにも関わらずLinuCができた経緯は良く分かりませんが（大人の事情があることは容易に想像できますが）、非常に紛らわしい。\nどうもLinuCは日本にローカライズされた資格を目指しているらしいけど、「Linux」というグローバルな技術要素を何故日本用にローカライズする必要があるのか、甚だ疑問です。\nどっちを取るかは、会社の報償制度やグローバルな資格が欲しいか、といった観点で判断すればいいでしょう。\nLPIC-2 中小規模のサーバー、ネットワークを管理するスキルが問われます。出題範囲はかなり広く、また細かなオプションまで問われます。サービスやコマンドによっては似て非なるオプションが存在するので、暗記力も問われます。そもそも暗記は技術の本質から外れてしまいそうだけど、試験だから割り切ってしまいましょう。\nバージョンによって出題範囲や各テーマの重みが変わってくるので、以下の公式ホームページを必ず確認しましょう。\nLPIC-2: Linux Engineerwww.lpi.org\nLPIC-2認定を受けるためには？ LPIC201試験及び202試験に合格すること、かつLPIC-1認定を受けていることが条件です。ただし、受験する順番は決められておらず、例えば「201→202→101→102」と受験しても問題ありません。（ちなみに僕はこのパターンです）\nこの場合、102合格時にLPIC-1とLPIC-2の同時認定となります。\nLPIC-2の範囲 公式ホームページから確認できます。見ての通り、出題範囲が広く、１つ１つの難易度も高いです。\n気を引き締めて勉強しましょう。\n受験の準備 受験はCBT方式です。自分で試験日、試験会場を予約する必要があります。\nLPICにアカウント登録する まずは、 https://www.lpi.org/ja/ からアカウントを作りましょう。\n試験日程、試験会場を予約する 受験申込はピアソンVUEから行います。 https://www.pearsonvue.co.jp/ からアカウントを作って、近くの試験場を選択して受験申込をしてしまいましょう。\n勉強法 始めは参考書で一通り覚えて、Ping-tで周回するイメージです。あとは実際にコマンドをたたいて体に覚えさせることも重要視してました。\n参考書 所謂「茶本」ってやつです。参考書はこれしか触ってません。\nPing-t 7割くらいは Ping-t で勉強してました。202、202のコンテンツ利用は有料になっています。6ヵ月利用で5,000円程度だったかと思います。\nhttps://ping-t.com/\n受験までに全ての問題を金にしました。\n周回していると問題を見るだけで答えが分かってしまうので本質的ではありません。そこは解説を隅まで理解するようにして、注意しながらやってました。\n実際に動かしてみる これが一番効果的だと思います。正直、LPIC-2にもなると暗記だけで対策するのは厳しいです。\n仮想マシンでLinuxサーバーをたてて一通りのコマンドを実行してみるのがよいでしょう。\n「試験日」を決めて取り掛かること 受験はCBT方式なので、受験日を自分で決めることができます。 これがメリットでもあり、デメリットでもあります。\n受験日はこの日と決めることで、メリハリある勉強が出来ると思います。\nではでは、頑張ってください。\n","description":"","id":24,"section":"posts","tags":["Linux","LPIC","LPIC-2"],"title":"「祝★LPIC-2認定」LPIC201,202に合格するために必要なこと","uri":"https://tommylife88.github.io/posts/2019/2019-08-02-linux-lpic2/"},{"content":"仕事でいまだに業務のノウハウとかをExcelファイルで管理してませんか？\nいちいちくそ重いExcelを起動して、セルを方眼紙みたくして、さらには手書きで変更履歴を書いて・・・考えるだけで鬱です。\nもうそんな運用はやめて、超快適なWikiプラットフォームを導入してWEBベースでノウハウを蓄積しよう。\n今回インストールするのは Growi になります。こちらはオープンソースソフトウェアでブラウザベースで動作します。\nMarkdownに対応しており、リアルタイムプレビュー機能付きなのでライティング、リライティングは爆速です。もちろん複数人OK、変更履歴も管理してくれます。\n開発はとても賑わっているようです。（→ Growi GitHub）ありがたや。\nただインストールするだけなら面白くないので、今回は仮想環境上で作っちゃいます。仮想環境はVagrant＋VirtuaBox。Vagrantとかの詳しい話は割愛します。\nうまくいけば、ホストPCが変更になってもWikiの移設が簡単簡単。\n構築したときの環境 筆者の環境\nホストPC：Windows 10 Home（64bit） CPU：Intel Core i7-7700HQ RAM：16GB Vagrant 2.2.3 VirtualBox 6.0.4 ゲストPC（仮想PC）：Ubuntu 18.04.2 LTS（bento/ubuntu-18.04） Docker 18.09.2 docker-compose 1.24.0-rc1 ※ホストPCだが、サーバー用途ならWindowsじゃなくてLinux系OSのほうが絶対良い。\n仮想環境を整える 公式に従い、ホストPCにVagrantインストール\nhttps://www.vagrantup.com/downloads\n公式に従い、ホストPCにVirtualBoxインストール\nhttps://www.virtualbox.org/wiki/Downloads\nVagrant＋VirtualBoxでゲストPC（仮想PC）を作る ホストPCでコマンドプロンプトを起動し、vagrant boxイメージを生成します。\nここでは作業ディレクトリとしてDドライブのvagrantフォルダにgrowiフォルダを作ることにする。\n1 2 3 4 5 D:\\vagrant\u0026gt; mkdir growi D:\\vagrant\u0026gt; cd growi D:\\vagrant\\growi\u0026gt; vagrant init bento/ubuntu-18.04 D:\\vagrant\\growi\u0026gt; vagrant up D:\\vagrant\\growi\u0026gt; vagrant ssh 自動生成されたVagrantファイルは後で弄る。\nゲストPCにSSHでログインできればOK。\nゲストPCの環境設定 ここからはゲストPC側の設定です。\nパッケージの最新化と日本語環境、タイムゾーン設定を行う。 1 2 3 4 5 6 7 8 9 10 11 12 vagrant@vagrant:~$ sudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y vagrant@vagrant:~$ sudo locale-gen ja_JP.UTF-8 vagrant@vagrant:~$ sudo localectl set-locale LANG=ja_JP.UTF-8 LANGUAGE=\u0026#34;ja_JP:ja\u0026#34; vagrant@vagrant:~$ exit #いったんゲストPCから抜ける D:\\vagrant\\growi\u0026gt; vagrant ssh vagrant@vagrant:~$ echo $LANG ja_JP.UTF-8 vagrant@vagrant:~$ sudo dpkg-reconfigure tzdata #[アジア]-[東京]を選択しましょう vagrant@vagrant:~$ exit #いったんゲストPCから抜ける D:\\vagrant\\growi\u0026gt; vagrant reload #ゲストPCを再起動 D:\\vagrant\\growi\u0026gt; vagrant ssh ゲストPCに Docker インストール 公式に従い、Dockerをインストールする。\nhttps://docs.docker.com/engine/install/\n1 2 3 4 5 6 7 8 vagrant@vagrant:~$ curl -fsSL https://get.docker.com/ | sudo sh vagrant@vagrant:~$ docker -v Docker version 18.06.2-ce, build 6d37f41 vagrant@vagrant:~$ sudo usermod -aG docker $USER #root権限なしで実行する vagrant@vagrant:~$ exit #いったんゲストPCから抜ける D:\\vagrant\\growi\u0026gt; vagrant ssh vagrant@vagrant:~$ groups #dockerに所属していることを確認する ゲストPCに Docker Compose インストール 公式に従い、Docker Composeをインストールする。\nhttp://docs.docker.jp/compose/install.html\n1 2 3 4 vagrant@vagrant:~$ sudo curl -L https://github.com/docker/compose/releases/download/1.24.0-rc1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose vagrant@vagrant:~$ sudo chmod +x /usr/local/bin/docker-compose vagrant@vagrant:~$ docker-compose -v docker-compose version 1.24.0-rc1, build 0f3d4dda ゲストPCに Growi インストール お持たせしました！ようやく「Growi」をインストールします。\nといってもコマンド一発でDockerさんがイイ感じにしれくれます。\nGitHubにある手順に従い、Growiをインストールする。\nhttps://github.com/weseek/growi-docker-compose\nホストPCからゲストPCにアクセスできるよう、docker-compose.ymlのportsを変更しておきます。\n1 2 3 vagrant@vagrant:~$ git clone https://github.com/weseek/growi-docker-compose.git growi vagrant@vagrant:~$ cd growi vagrant@vagrant:~$ vi docker-compose.yml 弄るのは１行だけ。\n1 2 3 ports: #- 127.0.0.1:3000:3000 # localhost only by default - 3000:3000 # ← modified アプリをビルドします。\n1 2 3 4 vagrant@vagrant:~$ docker-compose up #ひたすらログが流れて app_1 ・・・ : [production] Express server is listening on port 3000 #↑が表示されれば完了した 完了後、http://localhost:3000にアクセスするとGrowiのセットアップ画面が表示されるはず・・。がアクセスできません。\nVagrantのポートフォワードの設定が忘れてましたね。\nこのアプリはデフォルトで3000番ポートで待ち受けているようですので、ホストPCの12345番ポート（ここは任意）をゲストPCの3000番ポートにポートフォワード設定させます。\nCtrl+Cでアプリを止め、ゲストPCを抜けVagrantfileを弄ります。\nVagrantfileはこうなりました。こちらは超最小限の設定です。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 # -*- mode: ruby -*- # vi: set ft=ruby : # All Vagrant configuration is done below. The \u0026#34;2\u0026#34; in Vagrant.configure # configures the configuration version (we support older styles for # backwards compatibility). Please don\u0026#39;t change it unless you know what # you\u0026#39;re doing. Vagrant.configure(\u0026#34;2\u0026#34;) do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box = \u0026#34;bento/ubuntu-18.04\u0026#34; # Disable automatic box update checking. If you disable this, then # boxes will only be checked for updates when the user runs # `vagrant box outdated`. This is not recommended. # config.vm.box_check_update = false # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing \u0026#34;localhost:8080\u0026#34; will access port 80 on the guest machine. # NOTE: This will enable public access to the opened port # config.vm.network \u0026#34;forwarded_port\u0026#34;, guest: 80, host: 8080 config.vm.network \u0026#34;forwarded_port\u0026#34;, guest: 3000, host: 12345 # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine and only allow access # via 127.0.0.1 to disable public access # config.vm.network \u0026#34;forwarded_port\u0026#34;, guest: 80, host: 8080, host_ip: \u0026#34;127.0.0.1\u0026#34; # Create a private network, which allows host-only access to the machine # using a specific IP. # config.vm.network \u0026#34;private_network\u0026#34;, ip: \u0026#34;192.168.33.10\u0026#34; # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. # config.vm.network \u0026#34;public_network\u0026#34; # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder \u0026#34;../data\u0026#34;, \u0026#34;/vagrant_data\u0026#34; # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: # vb.memory = \u0026#34;1024\u0026#34; # end # # View the documentation for the provider you are using for more # information on available options. # Enable provisioning with a shell script. Additional provisioners such as # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the # documentation for more information about their specific syntax and use. # config.vm.provision \u0026#34;shell\u0026#34;, inline: \u0026lt;\u0026lt;-SHELL # apt-get update # apt-get install -y apache2 # SHELL end ゲストPCを再起動して、再度SSHではいりアプリを起動します。\ndockerイメージはビルド済みなのでstartコマンドでOK。\n1 2 3 4 5 6 7 D:\\vagrant\\growi\u0026gt; vagrant reload D:\\vagrant\\growi\u0026gt; vagrant ssh vagrant@vagrant:~$ cd growi vagrant@vagrant:~$ docker-compose start Starting mongo ... done Starting elasticsearch ... done Starting app ... done http://localhost:12345でセットアップ画面が表示されましたね。\nLAN内の他のPCからも、http://[ホストPCのIPアドレス]:12345でアクセス可能になっているはずです。\nlocalhostではOKで、外部からのIP指定でダメならホストPCのファイアウォールとかの設定が怪しいかも、ここでは割愛します。\nそもそもサーバー用途ならWindowsはおすすめしないです・・。\nではでは、良いGrowiライフを！\n","description":"","id":25,"section":"posts","tags":["Markdown","Wiki","vagrant","docker","docker-compose"],"title":"「超簡単」仮想環境でWiki「GROWI」を導入する（Markdown対応）","uri":"https://tommylife88.github.io/posts/2018/2018-12-13-growi-on-docker-on-vagrant/"},{"content":"こんな人に読んでほしい。\nLinux開発に触れてみたい Linux開発始めたいけど、いまいち何から手をつけたらいいか分からない Linuxのコマンドをデバッグしてみよう。\nコマンドのパッケージを特定してソースコードを落としてビルドしてデバックするところまでを実践的に触れることができると思う。\nlsコマンドをデバッグしてみる 本記事ではLinuxでよく使うコマンドlsをソースコートを落としてビルド、デバッグまでやってみる。\n環境 1 2 3 4 5 $ cat /etc/lsb-release DISTRIB_ID=Ubuntu DISTRIB_RELEASE=18.04 DISTRIB_CODENAME=bionic DISTRIB_DESCRIPTION=\u0026#34;Ubuntu 18.04.1 LTS\u0026#34; コマンドのパッケージを特定 まずは、lsコマンドのパッケージを特定します。\n1 2 3 4 $ which ls /bin/ls $ dpkg -S /bin/ls coreutils: /bin/ls lsは oreutilsっていうパッケージに含まれていることが分かりました。\nパッケージのソースをダウンロード ubuntu の公式パッケージであればapt sourceでソースコードをダウンロードできます。\nリポジトリからソースをダウンロードするため、sources.listのdeb-srcを有効にします。\n1 2 $ sudo su -c \u0026#34;grep \u0026#39;^deb \u0026#39; /etc/apt/sources.list | \\ sed \u0026#39;s/^deb/deb-src/g\u0026#39; \u0026gt; /etc/apt/sources.list.d/deb-src.list\u0026#34; リポジトリを更新しパッケージをダウンロードします。\n1 2 $ sudo apt update $ apt source coreutils lsをビルドする環境を整える apt build-depでソースパッケージをビルドするのに必要なソフトウェアをインストールしてくれます。便利。\n1 2 $ sudo apt install build-essential $ sudo apt build-dep coreutils ビルドする デバッグしたいので、デバッグ情報付加、最適化しないようにします。\n1 2 3 $ cd coreutils-8.28 $ ./configure CFLAGS=\u0026#34;-g3 -O0\u0026#34; $ make srcディレクトリ配下に実行ファイルが生成されます。\nデバッグする GNUデバッガgdbを使います。$ gdb (実行ファイル名)で起動します。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 $ cd src $ gdb ./ls (gdb) b main #main()関数にブレークポイントを貼る Breakpoint 1 at 0x4fc5: file src/ls.c, line 1445. (gdb) r #実行する Starting program: /home/coreutils-8.28/src/ls [Thread debugging using libthread_db enabled] Using host libthread_db library \u0026#34;/lib/x86_64-linux-gnu/libthread_db.so.1\u0026#34;. Breakpoint 1, main (argc=1, argv=0x7fffffffe388) at src/ls.c:1445 1445 { (gdb) n #ステップ実行する 1451 set_program_name (argv[0]); (gdb) 1452 setlocale (LC_ALL, \u0026#34;\u0026#34;); (gdb) 1453 bindtextdomain (PACKAGE, LOCALEDIR); main()関数にブレークポイントを貼ってステップ実行している（デバッグしている）例です。gdbの使い方に関してはマニュアルを参照しましょう。\nどうでしょう？たったこれだけですが、Linux開発の基本的なところである、「パッケージのソースを落としてビルド環境整えて、ビルド、デバッグする」という部分に触れることができましたね。\n","description":"","id":26,"section":"posts","tags":["Linux","gdb"],"title":"「Linuxに触れる」パッケージのソースを落としてビルド、デバッグする方法","uri":"https://tommylife88.github.io/posts/2018/2018-10-11-linux-debug-package/"},{"content":"本番環境のWordPressでテーマやCSS、プラグインを編集するには勇気がいるものです。\nそこでローカル環境にいま動いているWordPressを複製して、ローカル環境で気兼ねなくテストできる環境を作っておきましょう。\nローカル環境は「Local By Flywheel」で構築します。\nローカル環境にWordPress環境を構築する方法\nを参考にして下さい。\n本番環境→ローカル環境に複製する手順としては、\n本番環境をバックアップとってエクスポートする ローカル環境にインポートする だけなのですが、「All-in-One WP Migration」というプラグインを使うことで簡単に実現できます。\nhttps://ja.wordpress.org/plugins/all-in-one-wp-migration/\n「All-in-One WP Migration」による複環境製を行う 管理画面のプラグインの「新規追加」の画面にいって、「All-in-One WP Migration」をインストールし、有効化します。\n本番環境のバックアップ／エクスポートする 「All-in-One WP Migration」のバックアップ画面を表示します。\nこちらのプラグインですが、無料版だとインポート時の容量に512MBのサイズ制限がかかります。\n（有料版にアップグレードすることで無制限になるようです）\nメディアライブラリ内のデータ（アップロードしたデータ）をバックアップするとあっという間にサイズ制限を超えるので、メディアライブラリを対象から外しておきます。\nちょっとめんどくさいですが、メディアライブラリ内のデータはサーバーからFTPでダウンロードしましょう。\nただ、メディアライブラリに関しては、ローカル環境にインポートしなくても。画像が表示されないだけなので、基本的なサイトの動作には影響ないでしょう。\n「ファイル」を選択するとエクスポートが始まります。\nしばらく待ちましょう。\n完了したらダウンロードします。\nメディアライブラリを除外しても512MBを超えるようであれば、素直に有料版にしたほうが良いかもしれません。\nそれくらい便利なプラグインだと思います。\nローカル環境にインポートする 「Local By Flywheel」でローカル環境に構築したWordPressにインポートします。\nローカル環境のWordPressにも同じくプラグイン「All-in-One WP Migration」をインストールしておきます。\n「All-in-One WP Migration」のインポート画面を表示します。\n「ファイル」を選択して、指示通りにすすめていきます。\nアップロードサイズ制限に引っかかる場合、 最大アップロードファイルサイズを上げる方法 を参考にしましょう。\nしばらく待ちます。\nインポートが完了後、パーマリンクを更新します。\nデータベースの更新を行い完了です。\nログイン画面が表示されるはずですので、本番環境のIDとパスワードを入力しましょう。\nなお、メディアライブラリは、\\public\\wp-content\\uploads（ローカル環境のWordPressフォルダ）配下にアップロードされるので、本番環境からFTPでとってきたファイルをローカルのパスにコピーすることで画像を表示できます。\nまとめ どうでしょうか。超簡単ですよね。\nこれで本番環境と同じ環境をローカルで試すことができます。\n","description":"","id":27,"section":"posts","tags":["WordPress"],"title":"WordPress本番環境をローカル環境にコピー（複製）する方法","uri":"https://tommylife88.github.io/posts/2018/2018-03-02-wp-copy-to-local-env/"},{"content":"WordPressのバージョン4.x系から5.x系にバージョンアップする際に、今動いているサイト（テーマやプラグインいろいろ）がちゃんと動作するか？が一番の心配事になります。\n問題ないと言い切れるのならさっさと上げたいけど、サイトが止まると収益に影響するからなかなか踏み切れないんだよね。\nそこで今回、本番環境をローカル環境に複製して、ローカル環境でWordPress 5.Xの動作確認をしようというわけ。\n本記事では、 ローカル環境にWordPressを立ち上げる ところまで紹介します。\n超簡単です。\nLocal を使ったWordPress環境 WordPressのローカル環境を構築するのに使用するツールが「Local by Flywheel」になります。\nWindows上に仮想環境（VirtualBox）を作成して、仮想環境上でWordPressを動かす、ということをやってくれるアプリケーションです。\n仮想環境と聞くとなんやら小難しいかもしれませんが、ユーザーはアプリを介して操作するため直感的に操作できます。\nLocal インストール https://localwp.com/\n「FREE DOWNLOAD」を選択する。\n必要事項、\nOS「Windows」を選択する（MACなら「MAC」） Work Email Number of website を入力し、「GET IT NOW!」でインストーラーをダウンロード開始。\n完了後、実行ファイルを実行しインストールを開始する。\n途中、VirtualBoxによるユーザーアカウント制御画面が何回か表示されるが、全て許可する。\nローカル環境にWordPress環境を構築する 「Local by Flywheel」を起動して、環境を作っていきます。\nといってもポチポチしていくだけ。\n仮想環境を構築する 「LET’S GO!」をクリックする。\nWordPressの環境設定を行う 「CREATE A NEW SITE」をクリックする。\nサイト名を入力し「CONTINUE」をクリックする。\nサイト名は好きなように。\n「ADVANCED OPTIONS」でパスを設定しておくとよい。\nPHP、MySQLのバージョンを選択する。\nこちらはサーバーに合わせて選択する。\n分からなければデフォルト（Preferred）としておく。\nこちらは後で変更可能となってます。\nユーザー名、パスワードを入力し「ADD SITE」をクリックする。\nユーザー名、パスワードは管理者画面にログインするときに使うので覚えておく。\nなんでもよい。\nしばらくすると、HOME画面が表示されます。\nこれでWordPress環境は立ち上がってます。\nバージョンもしっかり5.Xですね。\nWordPressの管理者画面にログインする 「ADMIN」をクリックします。\n「Microsoft Edge」では表示されませんでした。\n「Google Chrome」では問題ないので、「Google Chrome」で開きましょう。 サイトを表示する 「VIEW SITE」をクリックします。\n「Microsoft Edge」では表示されませんでした。\n「Google Chrome」では問題ないので、「Google Chrome」で開きましょう。 WordPressの仮想環境を止める 仮想環境を止めたければ「STOP SIE」をクリックします。\nまとめ ローカル環境が整ったことで、いろいろ試行錯誤できるようになりました。\n次はいま動いている本番環境のWordPressをローカル環境にコピーします。\n","description":"","id":28,"section":"posts","tags":["WordPress","Local"],"title":"ローカル環境にWordPress環境を構築する方法","uri":"https://tommylife88.github.io/posts/2018/2018-03-01-wp-setup-local/"}]